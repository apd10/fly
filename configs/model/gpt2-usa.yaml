_target_: transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel
config:
  _target_: transformers.GPT2Config
  # Mistral's config: https://github.com/stanford-crfm/mistral/blob/main/conf/models/gpt2-small.yaml
  # However, reorder_and_upcast_attn slows things down
  reorder_and_upcast_attn: false
  scale_attn_by_inverse_layer_idx: true
  _attn_implementation: eager
  add_lth: true
  lth_int_dim: 128
  lth_final_dim: 24
  lth_bit_thold: 0.8
  lth_intended_top_k: 10
